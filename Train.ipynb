{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os,time,pickle\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "from torchvision import transforms\n",
    "from lib import networks,train_history,util,visualizer\n",
    "import itertools\n",
    "from torchvision import datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=2)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda:2' if torch.cuda.is_available() else 'cpu')\n",
    "if torch.backends.cudnn.enabled:\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "create web directory checkpoints/persona_3/web...\n"
     ]
    }
   ],
   "source": [
    "display_id=1\n",
    "display_winsize=256\n",
    "display_ncols=4\n",
    "display_server='http://localhost'\n",
    "display_port=8097\n",
    "display_env='main'\n",
    "name = 'persona_3'\n",
    "checkpoints_dir='checkpoints'\n",
    "\n",
    "vis = visualizer.Visualizer(display_id,display_winsize,display_ncols,display_server,display_port,display_env,\n",
    "                 name,checkpoints_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "g_input_nc = 3\n",
    "g_output_nc = 3\n",
    "d_input_nc = 3\n",
    "d_output_nc = 1\n",
    "\n",
    "ngf=32\n",
    "ndf=64\n",
    "nb = 9\n",
    "n_downsampling = 4\n",
    "\n",
    "load_size = 286\n",
    "fine_size = 256\n",
    "\n",
    "# original_input_size = 4\n",
    "batch_size = 1\n",
    "# progressive_rounds = 6\n",
    "\n",
    "lambda_A = 10.0\n",
    "lambda_B = 10.0\n",
    "lambda_idt = 0.5\n",
    "\n",
    "lr = 0.0002\n",
    "beta1 = 0.5\n",
    "beta2 = 0.999\n",
    "\n",
    "train_epoch = 100\n",
    "\n",
    "display_freq = 400\n",
    "print_freq = 400\n",
    "save_latest_freq = 400\n",
    "update_html_freq = 800"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initialize network with normal\n",
      "initialize network with normal\n",
      "initialize network with normal\n",
      "initialize network with normal\n",
      "---------- Networks initialized -------------\n",
      "G has 45620867 number of parameters\n",
      "D has 2764737 number of parameters\n",
      "-----------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "G_A = networks.generator(g_input_nc,g_output_nc,ngf,nb,n_downsampling=n_downsampling)\n",
    "G_B = networks.generator(g_input_nc,g_output_nc,ngf,nb,n_downsampling=n_downsampling)\n",
    "\n",
    "# G_A = networks.UnetGenerator(g_input_nc, g_output_nc, 7, ngf)\n",
    "# G_B = networks.UnetGenerator(g_input_nc, g_output_nc, 7, ngf)\n",
    "\n",
    "D_A = networks.discriminator(d_input_nc,d_output_nc,ndf)\n",
    "D_B = networks.discriminator(d_input_nc,d_output_nc,ndf)\n",
    "\n",
    "G_A,G_B,D_A,D_B = G_A.to(device),G_B.to(device),D_A.to(device),D_B.to(device)\n",
    "\n",
    "print('---------- Networks initialized -------------')\n",
    "for model_name,model in [('G',G_A),('D',D_A)]:\n",
    "    num_params = 0\n",
    "    for param in model.parameters():\n",
    "        num_params += param.numel()\n",
    "    print(str.format('{} has {} number of parameters', model_name, num_params))\n",
    "print('-----------------------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# src_data_path='data/real'\n",
    "# tgt_data_path = \"data/manga\"\n",
    "src_data_path='/data/persona_cyclegan/real'\n",
    "tgt_data_path =  '/data/persona_cyclegan/anime'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_loader\n",
    "transform = transforms.Compose([\n",
    "        transforms.Resize((load_size, load_size)),\n",
    "        transforms.RandomCrop(fine_size),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ColorJitter(0.1,0.1,0.1,0.1),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5))\n",
    "])\n",
    "\n",
    "train_loader_A = torch.utils.data.DataLoader(datasets.ImageFolder(src_data_path, transform), batch_size=batch_size, shuffle=True, drop_last=True)\n",
    "train_loader_B = torch.utils.data.DataLoader(datasets.ImageFolder(tgt_data_path, transform), batch_size=batch_size, shuffle=True, drop_last=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss\n",
    "GAN_loss = nn.MSELoss().to(device)\n",
    "L1_loss = nn.L1Loss().to(device)\n",
    "\n",
    "def D_loss_criterion(D_decision,device,zeros,trick=True):\n",
    "    if(zeros):\n",
    "        if(trick):\n",
    "            return GAN_loss(D_decision, torch.rand(D_decision.size(), device=device)/10.0)\n",
    "        return GAN_loss(D_decision, torch.zeros(D_decision.size(), device=device))\n",
    "    else:\n",
    "        if(trick):\n",
    "            return GAN_loss(D_decision, 1-torch.rand(D_decision.size(), device=device)/10.0)\n",
    "        return GAN_loss(D_decision, torch.ones(D_decision.size(), device=device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "G_optimizer = optim.Adam(itertools.chain(G_A.parameters(), G_B.parameters()), lr=lr, betas=(beta1, beta2))\n",
    "D_A_optimizer = optim.Adam(D_A.parameters(), lr=lr, betas=(beta1, beta2))\n",
    "D_B_optimizer = optim.Adam(D_B.parameters(), lr=lr, betas=(beta1, beta2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch_count=1\n",
    "niter = 3\n",
    "niter_decay = 100\n",
    "def lambda_rule(epoch):\n",
    "    lr_l = 1.0 - max(0, epoch + epoch_count - niter) / float(niter_decay + 1)\n",
    "    return lr_l\n",
    "schedulers = [lr_scheduler.LambdaLR(optimizer, lr_lambda=lambda_rule) for optimizer in [G_optimizer,D_A_optimizer,D_B_optimizer]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_hist = train_history.train_history(['G_gan_loss',\n",
    "                                          'G_cycle_loss',\n",
    "                                          'D_A_fake_loss',\n",
    "                                          'D_A_real_loss',\n",
    "                                          'D_B_fake_loss',\n",
    "                                          'D_B_real_loss'                                          \n",
    "                                          ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "starting_epoch=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "learning rate = 0.0002000\n",
      "learning rate = 0.0002000\n",
      "learning rate = 0.0002000\n",
      "(epoch: 0, iters: 0, time: 1.446, data: 0.039) G_gan_loss: 3.985 G_cycle_loss: 16.153 D_A_fake_loss: 2.067 D_A_real_loss: 2.005 D_B_fake_loss: 1.635 D_B_real_loss: 2.375 \n",
      "(epoch: 0, iters: 400, time: 0.688, data: 87.727) G_gan_loss: 1.073 G_cycle_loss: 6.795 D_A_fake_loss: 0.488 D_A_real_loss: 0.420 D_B_fake_loss: 0.415 D_B_real_loss: 0.383 \n",
      "(epoch: 0, iters: 800, time: 0.728, data: 176.547) G_gan_loss: 0.802 G_cycle_loss: 5.340 D_A_fake_loss: 0.251 D_A_real_loss: 0.272 D_B_fake_loss: 0.233 D_B_real_loss: 0.232 \n",
      "(epoch: 0, iters: 1200, time: 0.612, data: 265.380) G_gan_loss: 0.799 G_cycle_loss: 5.067 D_A_fake_loss: 0.239 D_A_real_loss: 0.269 D_B_fake_loss: 0.244 D_B_real_loss: 0.232 \n",
      "(epoch: 0, iters: 1600, time: 0.705, data: 353.813) G_gan_loss: 0.796 G_cycle_loss: 4.780 D_A_fake_loss: 0.238 D_A_real_loss: 0.263 D_B_fake_loss: 0.235 D_B_real_loss: 0.234 \n",
      "(epoch: 0, iters: 2000, time: 0.666, data: 442.605) G_gan_loss: 0.825 G_cycle_loss: 4.617 D_A_fake_loss: 0.232 D_A_real_loss: 0.267 D_B_fake_loss: 0.231 D_B_real_loss: 0.231 \n",
      "(epoch: 0, iters: 2400, time: 0.701, data: 531.439) G_gan_loss: 0.847 G_cycle_loss: 4.369 D_A_fake_loss: 0.226 D_A_real_loss: 0.256 D_B_fake_loss: 0.224 D_B_real_loss: 0.226 \n",
      "(epoch: 0, iters: 2800, time: 0.656, data: 620.108) G_gan_loss: 0.888 G_cycle_loss: 4.386 D_A_fake_loss: 0.225 D_A_real_loss: 0.257 D_B_fake_loss: 0.208 D_B_real_loss: 0.211 \n",
      "(epoch: 0, iters: 3200, time: 0.712, data: 708.589) G_gan_loss: 0.917 G_cycle_loss: 4.252 D_A_fake_loss: 0.216 D_A_real_loss: 0.240 D_B_fake_loss: 0.203 D_B_real_loss: 0.201 \n",
      "(epoch: 0, iters: 3600, time: 0.643, data: 797.118) G_gan_loss: 0.919 G_cycle_loss: 4.228 D_A_fake_loss: 0.220 D_A_real_loss: 0.251 D_B_fake_loss: 0.202 D_B_real_loss: 0.194 \n",
      "(epoch: 0, iters: 4000, time: 0.695, data: 885.766) G_gan_loss: 0.903 G_cycle_loss: 4.164 D_A_fake_loss: 0.217 D_A_real_loss: 0.243 D_B_fake_loss: 0.205 D_B_real_loss: 0.204 \n",
      "(epoch: 0, iters: 4400, time: 0.621, data: 974.321) G_gan_loss: 0.945 G_cycle_loss: 4.048 D_A_fake_loss: 0.205 D_A_real_loss: 0.232 D_B_fake_loss: 0.200 D_B_real_loss: 0.194 \n",
      "(epoch: 0, iters: 4800, time: 0.737, data: 1062.726) G_gan_loss: 0.933 G_cycle_loss: 4.072 D_A_fake_loss: 0.212 D_A_real_loss: 0.235 D_B_fake_loss: 0.199 D_B_real_loss: 0.199 \n",
      "(epoch: 0, iters: 5200, time: 0.668, data: 1151.246) G_gan_loss: 0.983 G_cycle_loss: 4.044 D_A_fake_loss: 0.203 D_A_real_loss: 0.229 D_B_fake_loss: 0.194 D_B_real_loss: 0.196 \n",
      "(epoch: 0, iters: 5600, time: 0.771, data: 1239.760) G_gan_loss: 0.971 G_cycle_loss: 3.951 D_A_fake_loss: 0.203 D_A_real_loss: 0.228 D_B_fake_loss: 0.192 D_B_real_loss: 0.198 \n",
      "(epoch: 0, iters: 6000, time: 0.662, data: 1328.363) G_gan_loss: 0.950 G_cycle_loss: 3.962 D_A_fake_loss: 0.200 D_A_real_loss: 0.218 D_B_fake_loss: 0.188 D_B_real_loss: 0.188 \n",
      "(epoch: 0, iters: 6400, time: 0.824, data: 1417.123) G_gan_loss: 0.895 G_cycle_loss: 3.788 D_A_fake_loss: 0.196 D_A_real_loss: 0.219 D_B_fake_loss: 0.293 D_B_real_loss: 0.303 \n",
      "(epoch: 0, iters: 6800, time: 0.654, data: 1505.900) G_gan_loss: 0.934 G_cycle_loss: 3.961 D_A_fake_loss: 0.204 D_A_real_loss: 0.220 D_B_fake_loss: 0.171 D_B_real_loss: 0.171 \n",
      "(epoch: 0, iters: 7200, time: 0.792, data: 1594.291) G_gan_loss: 0.952 G_cycle_loss: 3.835 D_A_fake_loss: 0.200 D_A_real_loss: 0.223 D_B_fake_loss: 0.177 D_B_real_loss: 0.182 \n",
      "(epoch: 0, iters: 7600, time: 0.732, data: 1682.821) G_gan_loss: 1.011 G_cycle_loss: 3.881 D_A_fake_loss: 0.204 D_A_real_loss: 0.219 D_B_fake_loss: 0.184 D_B_real_loss: 0.186 \n",
      "(epoch: 0, iters: 8000, time: 0.747, data: 1773.309) G_gan_loss: 0.967 G_cycle_loss: 3.738 D_A_fake_loss: 0.196 D_A_real_loss: 0.215 D_B_fake_loss: 0.178 D_B_real_loss: 0.186 \n",
      "(epoch: 0, iters: 8400, time: 0.637, data: 1861.926) G_gan_loss: 0.979 G_cycle_loss: 3.759 D_A_fake_loss: 0.204 D_A_real_loss: 0.221 D_B_fake_loss: 0.183 D_B_real_loss: 0.189 \n",
      "(epoch: 0, iters: 8800, time: 0.741, data: 1950.516) G_gan_loss: 0.989 G_cycle_loss: 3.660 D_A_fake_loss: 0.207 D_A_real_loss: 0.227 D_B_fake_loss: 0.187 D_B_real_loss: 0.187 \n",
      "(epoch: 0, iters: 9200, time: 0.668, data: 2039.043) G_gan_loss: 1.015 G_cycle_loss: 3.695 D_A_fake_loss: 0.194 D_A_real_loss: 0.208 D_B_fake_loss: 0.176 D_B_real_loss: 0.182 \n",
      "(epoch: 0, iters: 9600, time: 0.726, data: 2127.883) G_gan_loss: 1.064 G_cycle_loss: 3.712 D_A_fake_loss: 0.191 D_A_real_loss: 0.212 D_B_fake_loss: 0.170 D_B_real_loss: 0.177 \n",
      "(epoch: 0, iters: 10000, time: 0.639, data: 2216.951) G_gan_loss: 1.026 G_cycle_loss: 3.615 D_A_fake_loss: 0.198 D_A_real_loss: 0.211 D_B_fake_loss: 0.166 D_B_real_loss: 0.177 \n",
      "(epoch: 0, iters: 10400, time: 0.711, data: 2305.643) G_gan_loss: 0.991 G_cycle_loss: 3.549 D_A_fake_loss: 0.203 D_A_real_loss: 0.212 D_B_fake_loss: 0.171 D_B_real_loss: 0.181 \n",
      "(epoch: 0, iters: 10800, time: 0.670, data: 2394.306) G_gan_loss: 1.068 G_cycle_loss: 3.677 D_A_fake_loss: 0.194 D_A_real_loss: 0.203 D_B_fake_loss: 0.167 D_B_real_loss: 0.173 \n",
      "(epoch: 0, iters: 11200, time: 0.827, data: 2483.570) G_gan_loss: 1.026 G_cycle_loss: 3.645 D_A_fake_loss: 0.207 D_A_real_loss: 0.216 D_B_fake_loss: 0.168 D_B_real_loss: 0.172 \n",
      "(epoch: 0, iters: 11600, time: 0.648, data: 2572.246) G_gan_loss: 1.022 G_cycle_loss: 3.583 D_A_fake_loss: 0.196 D_A_real_loss: 0.216 D_B_fake_loss: 0.173 D_B_real_loss: 0.175 \n",
      "(epoch: 0, iters: 12000, time: 0.755, data: 2660.928) G_gan_loss: 1.071 G_cycle_loss: 3.541 D_A_fake_loss: 0.199 D_A_real_loss: 0.206 D_B_fake_loss: 0.160 D_B_real_loss: 0.161 \n",
      "(epoch: 0, iters: 12400, time: 0.641, data: 2749.951) G_gan_loss: 1.012 G_cycle_loss: 3.548 D_A_fake_loss: 0.197 D_A_real_loss: 0.210 D_B_fake_loss: 0.168 D_B_real_loss: 0.167 \n",
      "(epoch: 0, iters: 12800, time: 0.724, data: 2838.324) G_gan_loss: 1.033 G_cycle_loss: 3.472 D_A_fake_loss: 0.202 D_A_real_loss: 0.213 D_B_fake_loss: 0.160 D_B_real_loss: 0.166 \n",
      "(epoch: 0, iters: 13200, time: 0.636, data: 2926.696) G_gan_loss: 1.030 G_cycle_loss: 3.561 D_A_fake_loss: 0.187 D_A_real_loss: 0.204 D_B_fake_loss: 0.151 D_B_real_loss: 0.165 \n",
      "(epoch: 0, iters: 13600, time: 0.750, data: 3015.109) G_gan_loss: 1.085 G_cycle_loss: 3.518 D_A_fake_loss: 0.189 D_A_real_loss: 0.210 D_B_fake_loss: 0.160 D_B_real_loss: 0.171 \n",
      "(epoch: 0, iters: 14000, time: 0.646, data: 3103.583) G_gan_loss: 1.116 G_cycle_loss: 3.526 D_A_fake_loss: 0.180 D_A_real_loss: 0.198 D_B_fake_loss: 0.153 D_B_real_loss: 0.160 \n",
      "(epoch: 0, iters: 14400, time: 0.754, data: 3191.973) G_gan_loss: 1.110 G_cycle_loss: 3.479 D_A_fake_loss: 0.183 D_A_real_loss: 0.202 D_B_fake_loss: 0.149 D_B_real_loss: 0.158 \n",
      "(epoch: 0, iters: 14800, time: 0.675, data: 3280.447) G_gan_loss: 1.078 G_cycle_loss: 3.517 D_A_fake_loss: 0.191 D_A_real_loss: 0.212 D_B_fake_loss: 0.156 D_B_real_loss: 0.162 \n",
      "(epoch: 0, iters: 15200, time: 0.756, data: 3369.104) G_gan_loss: 1.037 G_cycle_loss: 3.396 D_A_fake_loss: 0.190 D_A_real_loss: 0.203 D_B_fake_loss: 0.150 D_B_real_loss: 0.159 \n",
      "(epoch: 0, iters: 15600, time: 0.660, data: 3457.920) G_gan_loss: 1.108 G_cycle_loss: 3.468 D_A_fake_loss: 0.194 D_A_real_loss: 0.208 D_B_fake_loss: 0.147 D_B_real_loss: 0.155 \n",
      "(epoch: 0, iters: 16000, time: 0.767, data: 3546.464) G_gan_loss: 1.062 G_cycle_loss: 3.460 D_A_fake_loss: 0.185 D_A_real_loss: 0.198 D_B_fake_loss: 0.154 D_B_real_loss: 0.164 \n",
      "(epoch: 0, iters: 16400, time: 0.681, data: 3635.307) G_gan_loss: 1.145 G_cycle_loss: 3.435 D_A_fake_loss: 0.172 D_A_real_loss: 0.196 D_B_fake_loss: 0.146 D_B_real_loss: 0.152 \n",
      "(epoch: 0, iters: 16800, time: 0.716, data: 3723.947) G_gan_loss: 1.078 G_cycle_loss: 3.394 D_A_fake_loss: 0.178 D_A_real_loss: 0.196 D_B_fake_loss: 0.148 D_B_real_loss: 0.166 \n",
      "(epoch: 0, iters: 17200, time: 0.680, data: 3812.448) G_gan_loss: 1.066 G_cycle_loss: 3.370 D_A_fake_loss: 0.186 D_A_real_loss: 0.201 D_B_fake_loss: 0.152 D_B_real_loss: 0.154 \n",
      "(epoch: 0, iters: 17600, time: 0.723, data: 3900.815) G_gan_loss: 1.157 G_cycle_loss: 3.373 D_A_fake_loss: 0.174 D_A_real_loss: 0.197 D_B_fake_loss: 0.145 D_B_real_loss: 0.153 \n",
      "(epoch: 0, iters: 18000, time: 0.656, data: 3989.195) G_gan_loss: 1.081 G_cycle_loss: 3.347 D_A_fake_loss: 0.182 D_A_real_loss: 0.193 D_B_fake_loss: 0.150 D_B_real_loss: 0.162 \n",
      "(epoch: 0, iters: 18400, time: 0.714, data: 4077.736) G_gan_loss: 1.124 G_cycle_loss: 3.358 D_A_fake_loss: 0.180 D_A_real_loss: 0.201 D_B_fake_loss: 0.146 D_B_real_loss: 0.162 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(epoch: 0, iters: 18800, time: 0.658, data: 4166.151) G_gan_loss: 1.094 G_cycle_loss: 3.320 D_A_fake_loss: 0.179 D_A_real_loss: 0.198 D_B_fake_loss: 0.158 D_B_real_loss: 0.158 \n",
      "(epoch: 0, iters: 19200, time: 0.756, data: 4254.520) G_gan_loss: 1.059 G_cycle_loss: 3.278 D_A_fake_loss: 0.177 D_A_real_loss: 0.198 D_B_fake_loss: 0.155 D_B_real_loss: 0.163 \n",
      "(epoch: 0, iters: 19600, time: 0.648, data: 4342.943) G_gan_loss: 1.120 G_cycle_loss: 3.294 D_A_fake_loss: 0.186 D_A_real_loss: 0.199 D_B_fake_loss: 0.147 D_B_real_loss: 0.154 \n",
      "(epoch: 0, iters: 20000, time: 0.729, data: 4431.548) G_gan_loss: 1.110 G_cycle_loss: 3.340 D_A_fake_loss: 0.185 D_A_real_loss: 0.197 D_B_fake_loss: 0.148 D_B_real_loss: 0.164 \n",
      "(epoch: 0, iters: 20400, time: 0.665, data: 4520.066) G_gan_loss: 1.127 G_cycle_loss: 3.367 D_A_fake_loss: 0.180 D_A_real_loss: 0.192 D_B_fake_loss: 0.141 D_B_real_loss: 0.154 \n",
      "learning rate = 0.0002000\n",
      "learning rate = 0.0002000\n",
      "learning rate = 0.0002000\n",
      "(epoch: 1, iters: 0, time: 0.439, data: 0.027) G_gan_loss: 1.132 G_cycle_loss: 3.357 D_A_fake_loss: 0.183 D_A_real_loss: 0.203 D_B_fake_loss: 0.148 D_B_real_loss: 0.164 \n",
      "(epoch: 1, iters: 400, time: 0.647, data: 88.186) G_gan_loss: 1.107 G_cycle_loss: 3.321 D_A_fake_loss: 0.183 D_A_real_loss: 0.197 D_B_fake_loss: 0.152 D_B_real_loss: 0.162 \n",
      "(epoch: 1, iters: 800, time: 0.750, data: 176.735) G_gan_loss: 1.079 G_cycle_loss: 3.268 D_A_fake_loss: 0.180 D_A_real_loss: 0.195 D_B_fake_loss: 0.146 D_B_real_loss: 0.159 \n",
      "(epoch: 1, iters: 1200, time: 0.638, data: 265.172) G_gan_loss: 1.106 G_cycle_loss: 3.296 D_A_fake_loss: 0.183 D_A_real_loss: 0.202 D_B_fake_loss: 0.144 D_B_real_loss: 0.157 \n",
      "(epoch: 1, iters: 1600, time: 0.732, data: 353.479) G_gan_loss: 1.076 G_cycle_loss: 3.271 D_A_fake_loss: 0.176 D_A_real_loss: 0.197 D_B_fake_loss: 0.143 D_B_real_loss: 0.155 \n",
      "(epoch: 1, iters: 2000, time: 0.649, data: 441.991) G_gan_loss: 1.127 G_cycle_loss: 3.257 D_A_fake_loss: 0.171 D_A_real_loss: 0.189 D_B_fake_loss: 0.143 D_B_real_loss: 0.162 \n",
      "(epoch: 1, iters: 2400, time: 0.767, data: 530.430) G_gan_loss: 1.115 G_cycle_loss: 3.254 D_A_fake_loss: 0.177 D_A_real_loss: 0.201 D_B_fake_loss: 0.141 D_B_real_loss: 0.156 \n",
      "(epoch: 1, iters: 2800, time: 0.747, data: 620.314) G_gan_loss: 1.109 G_cycle_loss: 3.193 D_A_fake_loss: 0.179 D_A_real_loss: 0.195 D_B_fake_loss: 0.151 D_B_real_loss: 0.159 \n",
      "(epoch: 1, iters: 3200, time: 0.752, data: 709.123) G_gan_loss: 1.148 G_cycle_loss: 3.271 D_A_fake_loss: 0.177 D_A_real_loss: 0.189 D_B_fake_loss: 0.138 D_B_real_loss: 0.159 \n",
      "(epoch: 1, iters: 3600, time: 0.697, data: 797.962) G_gan_loss: 1.135 G_cycle_loss: 3.201 D_A_fake_loss: 0.176 D_A_real_loss: 0.192 D_B_fake_loss: 0.141 D_B_real_loss: 0.153 \n",
      "(epoch: 1, iters: 4000, time: 0.762, data: 886.879) G_gan_loss: 1.090 G_cycle_loss: 3.185 D_A_fake_loss: 0.183 D_A_real_loss: 0.195 D_B_fake_loss: 0.148 D_B_real_loss: 0.156 \n",
      "(epoch: 1, iters: 4400, time: 0.693, data: 975.887) G_gan_loss: 1.093 G_cycle_loss: 3.181 D_A_fake_loss: 0.182 D_A_real_loss: 0.194 D_B_fake_loss: 0.143 D_B_real_loss: 0.161 \n",
      "(epoch: 1, iters: 4800, time: 0.781, data: 1065.071) G_gan_loss: 1.127 G_cycle_loss: 3.112 D_A_fake_loss: 0.170 D_A_real_loss: 0.192 D_B_fake_loss: 0.149 D_B_real_loss: 0.154 \n",
      "(epoch: 1, iters: 5200, time: 0.662, data: 1154.874) G_gan_loss: 1.121 G_cycle_loss: 3.204 D_A_fake_loss: 0.176 D_A_real_loss: 0.196 D_B_fake_loss: 0.143 D_B_real_loss: 0.154 \n",
      "(epoch: 1, iters: 5600, time: 0.769, data: 1243.168) G_gan_loss: 1.149 G_cycle_loss: 3.171 D_A_fake_loss: 0.168 D_A_real_loss: 0.183 D_B_fake_loss: 0.138 D_B_real_loss: 0.155 \n",
      "(epoch: 1, iters: 6000, time: 0.647, data: 1331.703) G_gan_loss: 1.114 G_cycle_loss: 3.246 D_A_fake_loss: 0.176 D_A_real_loss: 0.189 D_B_fake_loss: 0.148 D_B_real_loss: 0.152 \n",
      "(epoch: 1, iters: 6400, time: 0.711, data: 1420.060) G_gan_loss: 1.115 G_cycle_loss: 3.161 D_A_fake_loss: 0.170 D_A_real_loss: 0.185 D_B_fake_loss: 0.139 D_B_real_loss: 0.152 \n",
      "(epoch: 1, iters: 6800, time: 0.670, data: 1508.800) G_gan_loss: 1.116 G_cycle_loss: 3.241 D_A_fake_loss: 0.172 D_A_real_loss: 0.185 D_B_fake_loss: 0.139 D_B_real_loss: 0.150 \n",
      "(epoch: 1, iters: 7200, time: 0.766, data: 1597.681) G_gan_loss: 1.176 G_cycle_loss: 3.250 D_A_fake_loss: 0.157 D_A_real_loss: 0.178 D_B_fake_loss: 0.149 D_B_real_loss: 0.155 \n",
      "(epoch: 1, iters: 7600, time: 0.682, data: 1686.601) G_gan_loss: 1.138 G_cycle_loss: 3.235 D_A_fake_loss: 0.174 D_A_real_loss: 0.188 D_B_fake_loss: 0.140 D_B_real_loss: 0.142 \n",
      "(epoch: 1, iters: 8000, time: 0.773, data: 1775.773) G_gan_loss: 1.165 G_cycle_loss: 3.137 D_A_fake_loss: 0.172 D_A_real_loss: 0.186 D_B_fake_loss: 0.152 D_B_real_loss: 0.157 \n",
      "(epoch: 1, iters: 8400, time: 0.697, data: 1865.127) G_gan_loss: 1.146 G_cycle_loss: 3.148 D_A_fake_loss: 0.172 D_A_real_loss: 0.185 D_B_fake_loss: 0.137 D_B_real_loss: 0.156 \n",
      "(epoch: 1, iters: 8800, time: 0.759, data: 1954.643) G_gan_loss: 1.168 G_cycle_loss: 3.182 D_A_fake_loss: 0.176 D_A_real_loss: 0.188 D_B_fake_loss: 0.138 D_B_real_loss: 0.152 \n",
      "(epoch: 1, iters: 9200, time: 0.678, data: 2043.853) G_gan_loss: 1.156 G_cycle_loss: 3.186 D_A_fake_loss: 0.169 D_A_real_loss: 0.178 D_B_fake_loss: 0.140 D_B_real_loss: 0.154 \n",
      "(epoch: 1, iters: 9600, time: 0.771, data: 2133.332) G_gan_loss: 1.149 G_cycle_loss: 3.174 D_A_fake_loss: 0.155 D_A_real_loss: 0.181 D_B_fake_loss: 0.134 D_B_real_loss: 0.146 \n",
      "(epoch: 1, iters: 10000, time: 0.659, data: 2222.096) G_gan_loss: 1.155 G_cycle_loss: 3.133 D_A_fake_loss: 0.171 D_A_real_loss: 0.185 D_B_fake_loss: 0.132 D_B_real_loss: 0.148 \n",
      "(epoch: 1, iters: 10400, time: 0.726, data: 2310.596) G_gan_loss: 1.129 G_cycle_loss: 3.119 D_A_fake_loss: 0.176 D_A_real_loss: 0.185 D_B_fake_loss: 0.135 D_B_real_loss: 0.147 \n",
      "(epoch: 1, iters: 10800, time: 0.635, data: 2399.052) G_gan_loss: 1.171 G_cycle_loss: 3.194 D_A_fake_loss: 0.165 D_A_real_loss: 0.177 D_B_fake_loss: 0.141 D_B_real_loss: 0.154 \n",
      "(epoch: 1, iters: 11200, time: 0.722, data: 2487.402) G_gan_loss: 1.120 G_cycle_loss: 3.164 D_A_fake_loss: 0.169 D_A_real_loss: 0.184 D_B_fake_loss: 0.142 D_B_real_loss: 0.149 \n",
      "(epoch: 1, iters: 11600, time: 0.657, data: 2575.965) G_gan_loss: 1.129 G_cycle_loss: 3.141 D_A_fake_loss: 0.160 D_A_real_loss: 0.183 D_B_fake_loss: 0.134 D_B_real_loss: 0.147 \n",
      "(epoch: 1, iters: 12000, time: 0.748, data: 2664.350) G_gan_loss: 1.086 G_cycle_loss: 3.101 D_A_fake_loss: 0.168 D_A_real_loss: 0.182 D_B_fake_loss: 0.144 D_B_real_loss: 0.150 \n",
      "(epoch: 1, iters: 12400, time: 0.665, data: 2752.879) G_gan_loss: 1.120 G_cycle_loss: 3.176 D_A_fake_loss: 0.169 D_A_real_loss: 0.180 D_B_fake_loss: 0.127 D_B_real_loss: 0.145 \n",
      "(epoch: 1, iters: 12800, time: 0.760, data: 2841.240) G_gan_loss: 1.182 G_cycle_loss: 3.172 D_A_fake_loss: 0.173 D_A_real_loss: 0.185 D_B_fake_loss: 0.136 D_B_real_loss: 0.150 \n",
      "(epoch: 1, iters: 13200, time: 0.657, data: 2929.818) G_gan_loss: 1.105 G_cycle_loss: 3.140 D_A_fake_loss: 0.179 D_A_real_loss: 0.188 D_B_fake_loss: 0.132 D_B_real_loss: 0.150 \n",
      "(epoch: 1, iters: 13600, time: 0.737, data: 3018.599) G_gan_loss: 1.190 G_cycle_loss: 3.077 D_A_fake_loss: 0.172 D_A_real_loss: 0.187 D_B_fake_loss: 0.135 D_B_real_loss: 0.153 \n",
      "(epoch: 1, iters: 14000, time: 0.688, data: 3107.917) G_gan_loss: 1.104 G_cycle_loss: 3.024 D_A_fake_loss: 0.174 D_A_real_loss: 0.185 D_B_fake_loss: 0.140 D_B_real_loss: 0.151 \n",
      "(epoch: 1, iters: 14400, time: 0.790, data: 3197.187) G_gan_loss: 1.118 G_cycle_loss: 3.036 D_A_fake_loss: 0.174 D_A_real_loss: 0.181 D_B_fake_loss: 0.133 D_B_real_loss: 0.150 \n",
      "(epoch: 1, iters: 14800, time: 0.675, data: 3286.503) G_gan_loss: 1.117 G_cycle_loss: 3.013 D_A_fake_loss: 0.176 D_A_real_loss: 0.184 D_B_fake_loss: 0.136 D_B_real_loss: 0.158 \n",
      "(epoch: 1, iters: 15200, time: 0.780, data: 3375.808) G_gan_loss: 1.177 G_cycle_loss: 3.093 D_A_fake_loss: 0.170 D_A_real_loss: 0.189 D_B_fake_loss: 0.130 D_B_real_loss: 0.146 \n",
      "(epoch: 1, iters: 15600, time: 0.679, data: 3465.188) G_gan_loss: 1.134 G_cycle_loss: 3.064 D_A_fake_loss: 0.177 D_A_real_loss: 0.194 D_B_fake_loss: 0.139 D_B_real_loss: 0.157 \n",
      "(epoch: 1, iters: 16000, time: 0.759, data: 3554.206) G_gan_loss: 1.145 G_cycle_loss: 3.104 D_A_fake_loss: 0.175 D_A_real_loss: 0.184 D_B_fake_loss: 0.133 D_B_real_loss: 0.148 \n",
      "(epoch: 1, iters: 16400, time: 0.646, data: 3642.697) G_gan_loss: 1.173 G_cycle_loss: 3.086 D_A_fake_loss: 0.167 D_A_real_loss: 0.182 D_B_fake_loss: 0.128 D_B_real_loss: 0.145 \n"
     ]
    }
   ],
   "source": [
    "## print('training start!')\n",
    "\n",
    "num_pool = 80\n",
    "fake_A_pool = util.ImagePool(num_pool)\n",
    "fake_B_pool = util.ImagePool(num_pool)\n",
    "\n",
    "for epoch in range(train_epoch):\n",
    "    epoch_start_time = time.time()\n",
    "\n",
    "    for scheduler in schedulers:\n",
    "        scheduler.step()\n",
    "        print('learning rate = %.7f'%G_optimizer.param_groups[0]['lr'])\n",
    "    data_size = min(len(train_loader_A), len(train_loader_B))\n",
    "    \n",
    "    for i,((real_A,_),(real_B,_)) in enumerate(zip(train_loader_A, train_loader_B)):\n",
    "        G_A.train()\n",
    "        G_B.train()\n",
    "\n",
    "        iter_start_time = time.time()\n",
    "        # input image data\n",
    "        real_A = real_A.to(device)\n",
    "        real_B = real_B.to(device)\n",
    "\n",
    "        # Train generator G\n",
    "        \n",
    "        #fix D parameters\n",
    "        for model in [D_A, D_B]:\n",
    "            for param in model.parameters():\n",
    "                param.requires_grad = False\n",
    "        \n",
    "        # A -> B\n",
    "        fake_B = G_A(real_A)\n",
    "        D_B_fake_decision = D_B(fake_B)\n",
    "        G_A_loss = D_loss_criterion(D_B_fake_decision,device,zeros=False,trick=False)\n",
    "\n",
    "        # identity loss\n",
    "#         G_A_idt_loss = L1_loss(fake_B, real_A) * lambda_A * lambda_idt\n",
    "\n",
    "        # forward cycle loss\n",
    "        recon_A = G_B(fake_B)\n",
    "        cycle_A_loss = L1_loss(recon_A, real_A) * lambda_A\n",
    "\n",
    "        # B -> A\n",
    "        fake_A = G_B(real_B)\n",
    "        D_A_fake_decision = D_A(fake_A)\n",
    "        G_B_loss = D_loss_criterion(D_A_fake_decision,device,zeros=False,trick=False)\n",
    "\n",
    "        # identity loss\n",
    "#         G_B_idt_loss = L1_loss(fake_A, real_B) * lambda_B * lambda_idt\n",
    "\n",
    "        # backward cycle loss\n",
    "        recon_B = G_A(fake_A)\n",
    "        cycle_B_loss = L1_loss(recon_B, real_B) * lambda_B \n",
    "\n",
    "        # Back propagation\n",
    "        G_gan_loss = G_A_loss + G_B_loss\n",
    "        G_cycle_loss = cycle_A_loss + cycle_B_loss\n",
    "#         G_idt_loss = G_A_idt_loss + G_B_idt_loss\n",
    "\n",
    "#         G_loss = G_gan_loss + G_cycle_loss + G_idt_loss\n",
    "        G_loss = G_gan_loss + G_cycle_loss\n",
    "        \n",
    "        G_optimizer.zero_grad()\n",
    "        G_loss.backward()\n",
    "        G_optimizer.step()\n",
    "        \n",
    "        if i % display_freq == 0:\n",
    "            save_result = i % update_html_freq == 0\n",
    "            vis.display_current_results([real_A,fake_B,recon_A],starting_epoch+epoch, i,save_result)\n",
    "        \n",
    "        #train D parameters\n",
    "        for model in [D_A, D_B]:\n",
    "            for param in model.parameters():\n",
    "                param.requires_grad = True\n",
    "\n",
    "        # Train discriminator D_A\n",
    "        D_A_optimizer.zero_grad()\n",
    "       \n",
    "        D_A_real_decision = D_A(real_A)     \n",
    "        D_A_real_loss = D_loss_criterion(D_A_real_decision,device,zeros=False,trick=False)\n",
    "\n",
    "        fake_A = G_B(real_B)\n",
    "        fake_A = fake_A_pool.query(fake_A.detach())\n",
    "        D_A_fake_decision = D_A(fake_A)     \n",
    "        D_A_fake_loss = D_loss_criterion(D_A_fake_decision,device,zeros=True,trick=False)\n",
    "\n",
    "        # Back propagation\n",
    "        D_A_loss = 0.5*(D_A_fake_loss + D_A_real_loss)\n",
    "        D_A_loss.backward()\n",
    "        D_A_optimizer.step()\n",
    "\n",
    "        # Train discriminator D_B\n",
    "        D_B_optimizer.zero_grad()\n",
    "\n",
    "        D_B_real_decision = D_B(real_B)\n",
    "        D_B_real_loss = D_loss_criterion(D_B_real_decision,device,zeros=False,trick=False)         \n",
    "\n",
    "        fake_B = G_A(real_A)\n",
    "        fake_B = fake_B_pool.query(fake_B.detach())\n",
    "        D_B_fake_decision = D_B(fake_B)\n",
    "        D_B_fake_loss = D_loss_criterion(D_B_fake_decision,device,zeros=True,trick=False)\n",
    "\n",
    "        # Back propagation\n",
    "        D_B_loss = 0.5*(D_B_fake_loss + D_B_real_loss)\n",
    "        D_B_loss.backward()\n",
    "        D_B_optimizer.step()\n",
    "\n",
    "        train_hist.add_params([G_gan_loss,G_cycle_loss,D_A_fake_loss,D_A_real_loss,D_B_fake_loss,D_B_real_loss])\n",
    "\n",
    "        if i % print_freq == 0:\n",
    "            t_data = iter_start_time - epoch_start_time\n",
    "            losses = train_hist.check_current_avg()\n",
    "            t = (time.time() - iter_start_time) / batch_size\n",
    "            vis.print_current_losses(starting_epoch+epoch, i, losses, t, t_data)\n",
    "            if display_id > 0:\n",
    "                vis.plot_current_losses(starting_epoch+epoch, float(i) / data_size, losses)\n",
    "        \n",
    "        if i % save_latest_freq == 0:\n",
    "            torch.save(G_A.state_dict(), os.path.join(checkpoints_dir,name, 'G_A.pkl'))\n",
    "            torch.save(G_B.state_dict(), os.path.join(checkpoints_dir,name, 'G_B.pkl')) \n",
    "            torch.save(D_A.state_dict(), os.path.join(checkpoints_dir,name, 'D_A.pkl'))\n",
    "            torch.save(D_B.state_dict(), os.path.join(checkpoints_dir,name, 'D_B.pkl'))\n",
    "            train_hist.save_train(os.path.join(checkpoints_dir,name,  'train_hist.pkl'))\n",
    "            \n",
    "    if (epoch+starting_epoch)%10 == 0:\n",
    "        torch.save(G_A.state_dict(), os.path.join(checkpoints_dir,name, str(epoch+starting_epoch)+'G_A.pkl'))\n",
    "        torch.save(G_B.state_dict(), os.path.join(checkpoints_dir,name, str(epoch+starting_epoch)+'G_B.pkl')) \n",
    "        torch.save(D_A.state_dict(), os.path.join(checkpoints_dir,name, str(epoch+starting_epoch)+'D_A.pkl'))\n",
    "        torch.save(D_B.state_dict(), os.path.join(checkpoints_dir,name, str(epoch+starting_epoch)+'D_B.pkl'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
